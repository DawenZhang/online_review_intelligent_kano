{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "product_review_correlation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DawenZhang/online_review_intelligent_kano/blob/filled/product_review_correlation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfagghZ2b_-T",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown # product feature selection\n",
        "\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "product_feature_1 = \"filter\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_2 = \"warranty\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_3 = \"taste\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_4 = \"customer service\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_5 = \"carafe/pitcher\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_6 = \"travel mug\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_7 = \"chamber/tank\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_8 = \"cleaning\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_9 = \"pump\" #@param {type:\"string\"}\n",
        "\n",
        "product_feature_10 = \"water reservoir\" #@param {type:\"string\"}\n",
        "\n",
        "product_features = OrderedDict({\n",
        "    product_feature_1: product_feature_1.split(\"/\"),\n",
        "    product_feature_2: product_feature_2.split(\"/\"),\n",
        "    product_feature_3: product_feature_3.split(\"/\"),\n",
        "    product_feature_4: product_feature_4.split(\"/\"),\n",
        "    product_feature_5: product_feature_5.split(\"/\"),\n",
        "    product_feature_6: product_feature_6.split(\"/\"),\n",
        "    product_feature_7: product_feature_7.split(\"/\"),\n",
        "    product_feature_8: product_feature_8.split(\"/\"),\n",
        "    product_feature_9: product_feature_9.split(\"/\"),\n",
        "    product_feature_10: product_feature_10.split(\"/\")\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE_lr3AncV9v",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown # data preparation\n",
        "\n",
        "feature_vocabulary = []\n",
        "for feature_name in product_features:\n",
        "    for meta_feature_name in product_features[feature_name]:\n",
        "        feature_vocabulary.append(meta_feature_name)\n",
        "       \n",
        "      \n",
        "def check_features(something, product_features):\n",
        "    feature_list = []\n",
        "    for i in product_features:\n",
        "        for feature_tag in product_features[i]:\n",
        "            if something.lower() == feature_tag:\n",
        "                feature_list.append(i)\n",
        "    return feature_list\n",
        "  \n",
        "  \n",
        "#@markdown the product used for anomaly detection\n",
        "product_id = 1 #@param {type:\"integer\"}\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#@markdown the datasheet path; if you wish to upload files, leave them blank\n",
        "customer_reviews_datasheet_path = \"https://github.com/DawenZhang/online_review_intelligent_kano/raw/filled/provided/product_2/customer_reviews.csv\" #@param {type:\"string\"}\n",
        "entity_sentiment_datasheet_path = \"https://github.com/DawenZhang/online_review_intelligent_kano/raw/filled/provided/product_2/entity_sentiment.csv\" #@param {type:\"string\"}\n",
        "\n",
        "if customer_reviews_datasheet_path == \"\":\n",
        "  from google.colab import files\n",
        "  uploaded = {}\n",
        "  while len([*uploaded.keys()]) <= 0:\n",
        "    print(\"as the path field is left blank, please upload customer_reviews_datasheet\")\n",
        "    uploaded = files.upload()\n",
        "  import io\n",
        "  customer_reviews = pd.read_csv(io.StringIO(uploaded[[*uploaded.keys()][0]].decode('utf-8')))\n",
        "else:\n",
        "  customer_reviews = pd.read_csv(customer_reviews_datasheet_path)\n",
        "  \n",
        "customer_reviews['review_content'] = customer_reviews['review_content'].astype(str)\n",
        "\n",
        "product_reviews = customer_reviews.loc[customer_reviews['product_id'] == product_id, ['review_id', 'review_content', 'rating']].sort_values(by = ['review_id'])\n",
        "\n",
        "replaced_product_reviews = []\n",
        "for r_index, review in product_reviews.iterrows():\n",
        "    replaced_review = review[1]\n",
        "    for pf_name in product_features:\n",
        "      if len(product_features[pf_name]) > 1:\n",
        "        for pf_e_name in product_features[pf_name][1:]:\n",
        "          replaced_review = replaced_review.replace(pf_e_name, product_features[pf_name][0])\n",
        "    replaced_product_reviews.append(replaced_review)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_features = []\n",
        "\n",
        "for feature_name in product_features:\n",
        "    tf_features.append(product_features[feature_name][0])\n",
        "    \n",
        "vectorizer = TfidfVectorizer(vocabulary = tf_features, lowercase=True, ngram_range=(1, 2))\n",
        "tfidf = vectorizer.fit_transform(replaced_product_reviews)\n",
        "\n",
        "feature_entities = {}\n",
        "\n",
        "\n",
        "if entity_sentiment_datasheet_path == \"\":\n",
        "  from google.colab import files\n",
        "  uploaded = {}\n",
        "  while len([*uploaded.keys()]) <= 0:\n",
        "    print(\"as the path field is left blank, please upload entity_sentiment_datasheet\")\n",
        "    uploaded = files.upload()\n",
        "  import io\n",
        "  entity_sentiment = pd.read_csv(io.StringIO(uploaded[[*uploaded.keys()][0]].decode('utf-8')))\n",
        "else:\n",
        "  entity_sentiment = pd.read_csv(entity_sentiment_datasheet_path)\n",
        "\n",
        "for review_num in range(len(replaced_product_reviews)):\n",
        "    current_all_entities = entity_sentiment.loc[\n",
        "                                                (entity_sentiment['review_id'] == product_reviews.iloc[review_num]['review_id']) \n",
        "                                                & (entity_sentiment['product_id'] == product_id), \n",
        "                                                ['name', 'sentiment_score', 'sentiment_magnitude']\n",
        "                                                ]\n",
        "    current_entities = {}\n",
        "    \n",
        "    for e_index, entity in current_all_entities.iterrows():\n",
        "        \n",
        "        features = check_features(entity['name'], product_features)\n",
        "\n",
        "        if len(features) > 0:\n",
        "\n",
        "#             if entity['sentiment_magnitude'] == 0:\n",
        "#                 continue\n",
        "            \n",
        "            pending_entity = []\n",
        "            \n",
        "            pending_entity.append(tfidf[review_num, [*product_features].index(features[0])])\n",
        "            pending_entity.append(entity[1])\n",
        "            pending_entity.append(entity[2])\n",
        "            \n",
        "            for single_feature in features:\n",
        "                if single_feature not in current_entities:\n",
        "                    current_entities[single_feature] = []\n",
        "                current_entities[single_feature].append(pending_entity)\n",
        "                \n",
        "    for feature_name in current_entities:\n",
        "        if feature_name not in feature_entities:\n",
        "            feature_entities[feature_name] = []\n",
        "        adding_entity = [0, 0, 0, product_reviews.iloc[review_num][2]]\n",
        "        for meta_feature_entity in current_entities[feature_name]:\n",
        "            adding_entity[0] += meta_feature_entity[0]\n",
        "            adding_entity[1] += meta_feature_entity[1]\n",
        "            adding_entity[2] += meta_feature_entity[2]\n",
        "            \n",
        "        adding_entity[0] = adding_entity[0] / len(current_entities[feature_name])\n",
        "        adding_entity[1] = adding_entity[1] / len(current_entities[feature_name])\n",
        "\n",
        "        feature_entities[feature_name].append(adding_entity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV3v7aEbk1rd",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown # correlation analysis\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from scipy.stats import *\n",
        "correlation_method = \"Pearson\" #@param [\"Pearson\", \"Spearman\"]\n",
        "        \n",
        "from scipy import stats\n",
        "\n",
        "features_average = []\n",
        "\n",
        "for feature_name in feature_entities:\n",
        "    positive_sum = 0\n",
        "    positive_count = 0\n",
        "    negative_sum = 0\n",
        "    negative_count = 0\n",
        "    magnitude_sum = 0\n",
        "    magnitude_count = 0\n",
        "    scores = []\n",
        "    ratings = []\n",
        "    \n",
        "    for feature_entity in feature_entities[feature_name]:\n",
        "        if feature_entity[1] > 0:\n",
        "            positive_sum += (feature_entity[1] * feature_entity[0])\n",
        "            positive_count += 1\n",
        "        elif feature_entity[1] < 0:\n",
        "            negative_sum += (-feature_entity[1] * feature_entity[0])\n",
        "            negative_count += 1\n",
        "        magnitude_sum += feature_entity[2] * feature_entity[0]\n",
        "        magnitude_count += 1\n",
        "        \n",
        "        scores.append(feature_entity[1] * feature_entity[0])\n",
        "#         scores.append(feature_entity[1])\n",
        "        \n",
        "        ratings.append(feature_entity[3])\n",
        "        \n",
        "        if correlation_method == \"Pearson\":\n",
        "          correlation = pearsonr(scores, ratings)\n",
        "        else:\n",
        "          correlation = spearmanr(scores, ratings)\n",
        "        \n",
        "    features_average.append([\n",
        "                             0 if positive_count == 0 else positive_sum/positive_count,\n",
        "                             0 if negative_count == 0 else negative_sum/negative_count,\n",
        "                             0 if magnitude_count == 0 else magnitude_sum/magnitude_count,\n",
        "                             correlation,\n",
        "                             len(scores),\n",
        "                             feature_name\n",
        "                            ])\n",
        "    \n",
        "print(\"feature name\".ljust(30, ' '), \"coefficient\".ljust(30, ' '), \"p value\".ljust(30, ' '), \"evaluation sample size\".ljust(30, ' '))\n",
        "print()\n",
        "for fa in features_average:\n",
        "  print(str(fa[5]).ljust(30, ' '), str(\"{:.20f}\".format(fa[3][0])).ljust(30, ' '), str(\"{:.20f}\".format(fa[3][1])).ljust(30, ' '), str(fa[4]).ljust(30, ' '))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ-fdQxw4ciC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
